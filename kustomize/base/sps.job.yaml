apiVersion: batch/v1
kind: CronJob
metadata:
  name: sps-importer
spec:
  schedule: "0 3 * * *"
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 1
  failedJobsHistoryLimit: 1
  startingDeadlineSeconds: 300
  jobTemplate:
    spec:
      backoffLimit: 3
      template:
        spec:
          volumes:
            - name: static-xml
              configMap:
                name: static-xml
            - name: writeable-data
              persistentVolumeClaim:
                claimName: cephfs-volume
            - name: var-run
              emptyDir: {}
          containers:
            - name: sps-importer
              image: gitlab-registry.cern.ch/authzsvc/backends/docker-pyff
              imagePullPolicy: Always
              resources:
                requests:
                  cpu: 101m
                  memory: 2Gi
                limits:
                  cpu: 300m
                  memory: 2Gi
              volumeMounts:
                # Writeable directory for the metadata
                - mountPath: /tmp/pyff
                  name: writeable-data
                # Must be able to run pyff here
                - mountPath: /var/run
                  name: var-run
                # Static XML files to override the downloaded ones
                - mountPath: /tmp/overrides
                  name: static-xml
              envFrom:
                - configMapRef:
                    name: sps-importer-env
          restartPolicy: Never
